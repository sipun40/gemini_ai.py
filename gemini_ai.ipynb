{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sipun40/gemini_ai.py/blob/main/gemini_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qjcWFrEuc7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe57182-9437-4ac1-c97b-37b2d02a48fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HIYidrgpD-ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "NLFLgPqpvZ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ouq2MBdJwCg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "txL-TniiwWSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY=\"AIzaSyCABehd5i4c2W1ZfO07fDcE6d2o-7F4uBo \"\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "9HKcsnbNwhhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1=genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "ans=model1.generate_content(\"what is gemini ai?\")\n",
        "to_markdown(ans.text)\n"
      ],
      "metadata": {
        "id": "Jrg9qPlgw2gT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "de1811fd-52cd-45e1-ccb9-695b570f0da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Gemini AI is Google's most advanced AI model, designed to be multimodal and capable of handling various types of information, including text, code, audio, images, and video. It's built to be highly performant across a wide range of tasks and can be used in different ways, from data centers to mobile devices.\n> \n> Here's a breakdown of what makes Gemini AI significant:\n> \n> *   **Multimodal Capabilities:** Gemini is designed from the ground up to understand and reason across different types of data. This means it can process and combine information from text, images, audio, video, and code simultaneously.\n> *   **Advanced Reasoning and Problem-Solving:** It demonstrates strong capabilities in understanding context, reasoning, and solving complex problems. It excels in areas like mathematical reasoning, coding, and understanding nuanced language.\n> *   **Three Sizes:** Gemini is available in three different sizes to suit various needs:\n>     *   **Gemini Ultra:** The largest and most capable model, designed for highly complex tasks.\n>     *   **Gemini Pro:** A mid-sized model optimized for a wide range of tasks and currently powering some of Google's AI features, like Bard (now Gemini).\n>     *   **Gemini Nano:** A smaller model designed for on-device use, enabling AI-powered features on smartphones and other devices without needing to connect to the cloud.\n> *   **Integration with Google Products:** Google is integrating Gemini into many of its products and services, including:\n>     *   **Google AI Studio:**  A platform for developers to build and experiment with Gemini.\n>     *   **Google Cloud:** Gemini is available through Google Cloud's Vertex AI platform.\n>     *   **Android:** Gemini Nano powers on-device features for Android devices.\n>     *   **Workspace apps (Gmail, Docs, etc.):** Gemini helps with tasks like summarizing information and generating content.\n> *   **Ongoing Development:** Gemini is continuously being improved and updated with new capabilities and features.\n> \n> In essence, Gemini AI represents a significant advancement in AI technology, offering powerful capabilities for understanding and interacting with the world in a more comprehensive and nuanced way.\n"
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IMG20240830073336.Image\n",
        "\n",
        "# Replace 'actual/path/to/your/image/download.jpeg' with the actual path to your image file.\n",
        "image_path = 'C:\\Users\\KIIT\\Pictures\\Screenshots\\Screenshot 2025-04-08 145700.png'\n",
        "Image = IMG20240830073336(image_path)\n",
        "Image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "HP-rGpNBGepZ",
        "outputId": "bf00979c-289f-4699-9fba-a7ab42d3404f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-8-96c618d58bcf>, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-96c618d58bcf>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    image_path = 'C:\\Users\\KIIT\\Pictures\\Screenshots\\Screenshot 2025-04-08 145700.png'\u001b[0m\n\u001b[0m                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for m in genai.list_models():\n",
        "#   if 'generateContent' in m.supported_generation_methods:\n",
        "#     print(m.name)"
      ],
      "metadata": {
        "id": "ftz-Pr1f3o5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "ZdQkYYtzzFe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(img)\n",
        "\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "id": "WHHULo9MzRh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"solve this math problem step by step in hindi\", img], stream=True)\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "d5uHqfGvzX5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "id": "g_DGOSYxzfil"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}